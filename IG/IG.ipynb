{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Моделирование распределения длин N1 зоны антител человека**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import chisquare\n",
    "os.chdir(\"/Users/irina/Desktop/IG/small_phenotypes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Моделирование проводится отдельно для различных фенотипов (источников клеток) и только для productive последовательностей. Исходный датасет был разделен на фенотипы, взятые из названий статей. Создается словарь *phen_hist_dict*, ключи для которого - название фенотипа, а значения -  array, содержащий частоты длин N1 зоны (например, если нулевой элемент массива = 20, то N1 зона длины 1 встретилась в данных 20 раз). Те последовательности, где N1 зона была равна нулю, были исключены из анализа. Еще можно удалить клонов, которые были найдены с помощью тула Partis для того, чтобы выборка была случайной (а можно не удалять, тогда нужно пропустить следующий блок)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_ids = [] #list of ids from Partis output, the first id from each clonal family\n",
    "for n in range(1,162):\n",
    "    try:\n",
    "        aa= pd.read_csv(\"./1-162/\" + str(n) + '-cluster-annotations.csv')\n",
    "        for _,row in aa.iterrows():\n",
    "            list_ids.append(row[\"unique_ids\"].split(\":\")[0])\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cut_num(paper_name):\n",
    "    x = re.search('[0-9]+\\)\\s', paper_name)    \n",
    "    start_pos = x.end()\n",
    "    return paper_name[start_pos:]\n",
    "\n",
    "def make_ID_dict(fname):\n",
    "    ID_dict = {}\n",
    "    counter = 0\n",
    "    with open(fname,'r') as f:\n",
    "        for line in f:\n",
    "            counter += 1\n",
    "            if counter%3 == 1:\n",
    "                ID = line.strip()\n",
    "            elif counter%3 == 2:\n",
    "                paper = line.strip()\n",
    "                ID_dict[ID] = paper\n",
    "    return ID_dict\n",
    "\n",
    "handle = pd.ExcelFile('table_phenotypes.xlsx')\n",
    "data = handle.parse(sheetname=\"Sheet1\",skiprows=1)\n",
    "phenotypes = set(data.columns)\n",
    "phen_exclude = set(['Unnamed: 23', '//T helper cells', 'Unnamed: 31', '//SHM and Absence of AID','//Primary cold agglutinin disease','//Anti-platelets Ab','//Human Ig combinatorial library from genomic V segments and synthetic CDR3 fragments','//In vitro assembly and Sterile DJH rearrangements','//Women with myasthenia: evidence for immunization by fetal antigen','//Xeroderma pigmentosum','//IgD-only B cells','//T helper cells'])\n",
    "phenotypes.difference_update(phen_exclude)\n",
    "\n",
    "paper_dict = {cut_num(paper):phen for phen in phenotypes for paper in data[phen] if (type(paper)==str and ')' in paper)}\n",
    "ID_dict = make_ID_dict('id_title-productive_seqs.txt')\n",
    "ID_phen_dict = {ID:paper_dict[paper] for ID,paper in ID_dict.items() if paper in paper_dict}\n",
    "\n",
    "len_data = pd.read_csv('Nt_seq.csv') #V-quest output\n",
    "len_data = len_data.loc[len_data[\"lens_n1\"]>0]\n",
    "phen_hist_dict = {phenotype:np.zeros((1000)) for phenotype in phenotypes}\n",
    "for _,row in len_data.iterrows():\n",
    "    current_ID = row['Sequence ID']\n",
    "    #if current_ID in list_ids: #if you don't need filter sequences from one clonal family, just delete or comment this line\n",
    "    if current_ID in ID_phen_dict:\n",
    "        phen_hist_dict[ID_phen_dict[current_ID]][int(row['lens_n1']) - 1] += 1\n",
    "sortednames=sorted(phen_hist_dict.keys(), key=lambda x:x.lower()) \n",
    "phen_hist_dict = {sor:phen_hist_dict[sor] for sor in sortednames}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция *pnpe* содержит модель распределения длин N1 зоны. Вероятность нулевой длины = 0. Функция *likelihood* нужна для поиска оптимальных параметров модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def pnpe(n, pp, pn, pe):\n",
    "    if n > 0:\n",
    "        prob = ((pe**2*pn*pp**2*((n-1)*(pe*(1-pp))**(n-2)))/((pn-pp)*(pe+pp-pe*pp)**(n+2))) + ((pe*pn*pp**2*(pe*(1-pn))**n)/((pn-pp)**2*(pe-pe*pn)*(pe+pn-pe*pn)**(n+1))) - ((pe*pn*pp**2 * (pe*(1-pp))**n * (pe-2*pn + 3*pp + 2* pe*pn - 3 *pe*pp))/((pn - pp)**2*(pe-pe*pp)*(pe + pp - pe*pp)**(n+2)))\n",
    "        return prob\n",
    "    elif n == 0:\n",
    "        prob = 0\n",
    "        return prob\n",
    "    else:\n",
    "        prob = ((pe**2*pn*pp**2*((1/(pe**2*(pp-1)**2))+(((n-1)*((-pe*(pp-1))/(pe+pp-pe*pp))**(n-2))/((pe+pp-pe*pp)**2))))/((pn-pp)*(pe-pp-pe*pp)**2)) - ((pn*pp**2*(pe-1)**3)/((pe+pn - pe*pn)*(pe+pp - pe*pp)**2)) +((pe*pn*pp**2*(((-pe*(pn-1))/(pe+pn-pe*pn))**n-1))/((pn-pp)**2*(pe-pe*pn)*(pe+pn-pe*pn))) - ((pe*pn*pp**2*(((-pe*(pp-1))/(pe+pp-pe*pp))**n-1)*(pe-2*pn+3*pp+2*pe*pn - 3*pe*pp))/((pn - pp)**2*(pe-pe*pp)*(pe+pp-pe*pp)**2))\n",
    "        return prob\n",
    "\n",
    "def likelihood(params):\n",
    "    pp, pn, pe = params[0], params[1], params[2]\n",
    "    return -np.sum([(y_exp_norm[x0-1])*np.log(pnpe(x0, pp, pn, pe)) for x0 in x_exp])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция *optimize_initial_guess* подбирает начальные приближенные параметры для функции максимального правдоподобия. Поскольку для этого надо перебрать 1 тыс комбинаций, лучше не запускать ее каждый раз. В прошлый раз оптимальный initial guess был 0.91, 0.81, 0.01."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def optimize_initial_guess():\n",
    "    aa = np.meshgrid(np.arange(0.01, 1, 0.1), np.arange(0.01, 1, 0.1), np.arange(0.01, 1, 0.1)) #чтобы перебрать 1 млн комбинаций, измените шаг на 0.01\n",
    "    coord_list = [entry.ravel() for entry in aa]\n",
    "    points = np.vstack(coord_list).T\n",
    "    res_dict = {}\n",
    "    n = 0\n",
    "    for point in points:\n",
    "        result = minimize(likelihood, x0=point, bounds=((0.2, 0.999), (0.01, 0.999), (0.01, 0.999))) #minimization of ML function\n",
    "        res_dict[result.fun] = point\n",
    "        n+=1\n",
    "    key_list = [x for x in res_dict.keys() if str(x) != 'nan']\n",
    "    return res_dict[min(key_list)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "parametrs = []\n",
    "all_data = []\n",
    "#find the parameters for each phenotype\n",
    "for phen in phen_hist_dict:\n",
    "    if sum(phen_hist_dict[phen]) >= 80: #only for more than 80 samples\n",
    "        x_exp = list(np.arange(1, 51))\n",
    "        y_exp = list(phen_hist_dict[phen][:50])\n",
    "        y_exp_norm = [y / sum(y_exp) for y in y_exp]\n",
    "        #initial_guess = optimize_initial_guess() #Если не хочется подбирать изначальные параметры, надо закомментировать эту строку и активировать следующую\n",
    "        initial_guess = np.array([0.91, 0.81, 0.01])\n",
    "        result = minimize(likelihood, x0=initial_guess, bounds=((0.2, 0.999), (0.01, 0.999), (0.001, 0.999))) #minimization of ML function\n",
    "        coeff = result.x\n",
    "        y = [pnpe(z, coeff[0], coeff[1], coeff[2]) for z in x_exp]\n",
    "        parametrs.append([coeff, phen])\n",
    "        all_data.append([x_exp, y_exp_norm, y, phen])\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сохранить параметры модели для каждого фенотипа в csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dd = []\n",
    "for i in range(len(all_data)):\n",
    "    ss = []\n",
    "    for j in range(3):\n",
    "        ss.append(parametrs[i][0][j])\n",
    "    dd.append([ss + [str(parametrs[i][1])]])\n",
    "\n",
    "data = [tuple(i[0]) for i in dd]\n",
    "labels = ['pp', 'pn', 'pe', 'phenotype']\n",
    "par_df = pd.DataFrame.from_records(parametrs)\n",
    "par_df.to_csv(\"Phenotypes_params.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Визуализация. Красная линия - экспериментальное распределение, синяя - смоделированное. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(25, 25)) #visualization\n",
    "columns = 4\n",
    "rows = 4\n",
    "for i in range(1, 10):\n",
    "    fig.add_subplot(rows, columns, i)\n",
    "    plt.plot(all_data[i - 1][0], all_data[i - 1][1], color=\"red\")\n",
    "    plt.plot(all_data[i - 1][0], all_data[i - 1][2], color=\"blue\")\n",
    "    plt.xlabel(\"Length of N1\")\n",
    "    plt.ylabel(\"Prob\")\n",
    "    plt.title(str(all_data[i - 1][3])[2:30])\n",
    "plt.savefig('pheno.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попытка проверить модель с помощью хи-квадрат с треском провалилась. Нужны не частоты, а число наблюдений?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Power_divergenceResult(statistic=0.18998743757861111, pvalue=1.0) Acute viral infection\n",
      "Power_divergenceResult(statistic=0.13614530441209263, pvalue=1.0) Chronic lymphocytic leukemia\n",
      "Power_divergenceResult(statistic=0.087993912993141132, pvalue=1.0) Health bone marrow\n",
      "Power_divergenceResult(statistic=0.03867469328035239, pvalue=1.0) Health periphery\n",
      "Power_divergenceResult(statistic=0.31381790883448235, pvalue=1.0) Healthy elderly humans\n",
      "Power_divergenceResult(statistic=0.16819723585696292, pvalue=1.0) Hepatitis C virus infection\n",
      "Power_divergenceResult(statistic=0.61648695904553352, pvalue=1.0) Hodgkin lymphoma\n",
      "Power_divergenceResult(statistic=0.24775715281716892, pvalue=1.0) Infectious mononucleosis\n",
      "Power_divergenceResult(statistic=1.1064663613593411, pvalue=1.0) Multiple sclerosis\n",
      "Power_divergenceResult(statistic=0.79413202914435765, pvalue=1.0) Non-Hodgkin lymphomas\n",
      "Power_divergenceResult(statistic=0.4306546107603445, pvalue=1.0) Ocular adnexal lymphoma\n",
      "Power_divergenceResult(statistic=0.05078318065305721, pvalue=1.0) Preterm infants and fetum\n",
      "Power_divergenceResult(statistic=0.61965228838710007, pvalue=1.0) Systemic lupus erythematosus\n",
      "Power_divergenceResult(statistic=0.50342897736545145, pvalue=1.0) Wegener's granuloma\n",
      "Power_divergenceResult(statistic=0.11578400628745335, pvalue=1.0) X-linked hyper-IgM syndrome\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(parametrs)):\n",
    "    print(chisquare(all_data[i][1],  f_exp=all_data[i][2], ddof = 3), str(all_data[i][3])[2:30] )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Power_divergenceResult(statistic=189.98743757861112, pvalue=2.069917417123229e-19) Acute viral infection\n",
      "Power_divergenceResult(statistic=136.14530441209266, pvalue=7.5225230148338552e-11) Chronic lymphocytic leukemia\n",
      "Power_divergenceResult(statistic=87.993912993141123, pvalue=0.00019109394535218936) Health bone marrow\n",
      "Power_divergenceResult(statistic=38.674693280352386, pvalue=0.76972869342499217) Health periphery\n",
      "Power_divergenceResult(statistic=313.81790883448235, pvalue=1.4923870546006443e-41) Healthy elderly humans\n",
      "Power_divergenceResult(statistic=168.19723585696292, pvalue=7.9498494019800591e-16) Hepatitis C virus infection\n",
      "Power_divergenceResult(statistic=616.48695904553324, pvalue=7.387534169085388e-101) Hodgkin lymphoma\n",
      "Power_divergenceResult(statistic=247.75715281716896, pvalue=1.9027540179074406e-29) Infectious mononucleosis\n",
      "Power_divergenceResult(statistic=1106.4663613593411, pvalue=1.1083730661465275e-201) Multiple sclerosis\n",
      "Power_divergenceResult(statistic=794.13202914435772, pvalue=5.0736624036643022e-137) Non-Hodgkin lymphomas\n",
      "Power_divergenceResult(statistic=430.6546107603445, pvalue=6.4343760736859518e-64) Ocular adnexal lymphoma\n",
      "Power_divergenceResult(statistic=50.783180653057208, pvalue=0.29069014424192535) Preterm infants and fetum\n",
      "Power_divergenceResult(statistic=619.65228838710004, pvalue=1.6979283630138947e-101) Systemic lupus erythematosus\n",
      "Power_divergenceResult(statistic=503.42897736545149, pvalue=3.0941486390153234e-78) Wegener's granuloma\n",
      "Power_divergenceResult(statistic=115.78400628745335, pvalue=6.1023525889990728e-08) X-linked hyper-IgM syndrome\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(parametrs)):\n",
    "    print(chisquare([i*1000 for i in all_data[i][1]],  f_exp=[i*1000 for i in all_data[i][2]], ddof = 3), str(all_data[i][3])[2:30] )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.069767441860465115,\n",
       " 0.071881606765327691,\n",
       " 0.10782241014799154,\n",
       " 0.11416490486257928,\n",
       " 0.084566596194503171,\n",
       " 0.076109936575052856,\n",
       " 0.063424947145877375,\n",
       " 0.07399577167019028,\n",
       " 0.057082452431289642,\n",
       " 0.040169133192389003,\n",
       " 0.044397463002114168,\n",
       " 0.046511627906976744,\n",
       " 0.040169133192389003,\n",
       " 0.029598308668076109,\n",
       " 0.023255813953488372,\n",
       " 0.014799154334038054,\n",
       " 0.0063424947145877377,\n",
       " 0.0084566596194503175,\n",
       " 0.0042283298097251587,\n",
       " 0.012684989429175475,\n",
       " 0.0042283298097251587,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0042283298097251587,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0021141649048625794,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data[3][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 0.2       ,  0.07460483,  0.30957584]), '//Health bone marrow']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parametrs[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[33.0,\n",
       " 34.0,\n",
       " 51.0,\n",
       " 54.0,\n",
       " 40.0,\n",
       " 36.0,\n",
       " 30.0,\n",
       " 35.0,\n",
       " 27.0,\n",
       " 19.0,\n",
       " 21.0,\n",
       " 22.0,\n",
       " 19.0,\n",
       " 14.0,\n",
       " 11.0,\n",
       " 7.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 2.0,\n",
       " 6.0,\n",
       " 2.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 2.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(phen_hist_dict[\"//Health bone marrow\"][:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
